---
layout: archive
title: "PPIE"
permalink: /ppie/
author_profile: true
---

## PPIE Materials for AI literacy 
Much of my worked is centred around working with members of the public on AI topics, co-creating educational materials around AI, and thinking about critical AI literacy. Below are some useful resources I have used in different public and patient involvement and engagement (PPIE) groups to prompt discussion around AI and to grow critical AI literacy. 

**Animations**

[What is Artificial Intelligence](https://www.youtube.com/watch?v=N4NZoTW8ekY&ab_channel=DepartmentofSurgeryandCancer) This is a short animation co-produced with PPIE contributors to help explain what AI is, in simple and easy to understand language. The animation is available in English. I find all the resources co-created by the NIHR Imperial BRC useful, you can check them out [here](https://imperialbrc.nihr.ac.uk/2023/06/26/navigating-digital-health-a-guide-to-data-and-artificial-intelligence-in-healthcare/).

[Understanding Patient Data](https://understandingpatientdata.org.uk/introducing-patient-data) This is series of well made and well researched animations explaining patient health data in the UK. 

**Facial Recognition:** 

[How Normal Am I?](https://www.hownormalami.eu/) This tool allows users to experience a facial recognition tool, by sharing access to their webcam an AI tool rates your face, predicting your age, BMI and attractiveness. This is a useful starting point for wider conversations about what facial recognition is useful, and not useful for, the subjectivity of many measures such as attractiveness, and how easy it is to manipulate if you change the lighting, smile, or put on a hat. No personal data is stored. 

**Classification**

[Teachable Machine](https://teachablemachine.withgoogle.com/) provided by Google, is a quick and easy way to show people how classification models work. You can upload images and the model will train a simple classification model. I use this to demostrate how important the data input is, the potential for bias given different features and the embedded values that are in AI models. For example if you train a model on classifying emotions in human faces, but only include smiling, angry and sad faces scrapped from Google Images, you can demostrate that a) the model doesn't work well with other images, b) facial recognition is a contested area, there is no one universal way to portray emotions and c) many model creators don't get permission for the data that they train their models with. 

**Images**

[Better Images of AI](https://betterimagesofai.org/images) provides an incredible resource of AI images that are freely available to use. This image library moves beyond white robots and blue brains that are commonly used to depict AI, and provide thoughtful and sociotechnical understandings of AI. 

